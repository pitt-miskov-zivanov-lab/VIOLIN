{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-14T19:00:17.655753Z",
     "start_time": "2024-07-14T19:00:06.877978Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sys \n",
    "import glob\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'src/violin/')))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from violin.in_out import preprocessing_model, preprocessing_reading, output\n",
    "from violin.scoring import score_reading\n",
    "from violin.network import node_edge_list\n",
    "from violin.visualize_violin import visualize \n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T21:17:17.067493Z",
     "start_time": "2024-07-14T21:17:16.707268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Parameters ## \n",
    "approach = '1'\n",
    "kind_dict = {\"strong corroboration\" : 2, \n",
    "                \"empty attribute\" : 1,\n",
    "                \"indirect interaction\" : 3,\n",
    "                \"path corroboration\" : 5,\n",
    "                \"specification\" : 7,\n",
    "                \"hanging extension\" : 40, \n",
    "                \"full extension\" : 39, \n",
    "                \"internal extension\" : 38,  \n",
    "                \"dir contradiction\" : 11,\n",
    "                \"sign contradiction\" : 10, \n",
    "                \"att contradiction\" : 9,\n",
    "                \"dir mismatch\" : 20,\n",
    "                \"path mismatch\" : 19,\n",
    "                \"self-regulation\" : 18}\n",
    "match_dict = {\"source present\" : 1, \n",
    "                \"target present\" : 100, \n",
    "                \"both present\" : 10, \n",
    "                \"neither present\" : 0.1}\n",
    "evidence_scoring_cols = [\"Regulator Name\", \"Regulator Type\", \"Regulator Subtype\", \"Regulator HGNC Symbol\", \"Regulator Database\", \"Regulator ID\", \"Regulator Compartment\", \"Regulator Compartment ID\",\n",
    "                        \"Regulated Name\", \"Regulated Type\", \"Regulated Subtype\", \"Regulated HGNC Symbol\", \"Regulated Database\", \"Regulated ID\", \"Regulated Compartment\", \"Regulated Compartment ID\",\n",
    "                        \"Sign\", \"Connection Type\", \"Mechanism\", \"Site\",\n",
    "                        \"Cell Line\", \"Cell Type\", \"Tissue Type\", \"Organism\"]\n",
    "attributes = ['Regulated Compartment ID', 'Regulator Compartment ID']\n",
    "#attributes = ['Regulated Compartment ID', 'Regulator Compartment ID', 'Mechanism', 'Cell Line', 'Cell Type', 'Tissue Type', 'Organism']"
   ],
   "id": "ed008fb808259739",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T22:32:26.171523Z",
     "start_time": "2024-07-14T22:32:21.882402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reader = 'LLAMA'\n",
    "model_files = ['input/models/SkMel133_biorecipe.xlsx', 'input/models/ModelB_discrete_biorecipe.xlsx']\n",
    "reading_A_files = glob.glob(f'input/interactions/{reader}/RA*.xlsx')\n",
    "reading_B_files = glob.glob(f'input/interactions/{reader}/RB*.xlsx')\n",
    "\n",
    "model_A_df = preprocessing_model(model_files[0])\n",
    "model_B_df = preprocessing_model(model_files[1])\n",
    "\n",
    "graph_A = node_edge_list(model_A_df)\n",
    "graph_B = node_edge_list(model_B_df)"
   ],
   "id": "49cce84d0668c72b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data collections",
   "id": "4ab75e766d2aedd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T22:32:34.579806Z",
     "start_time": "2024-07-14T22:32:26.994822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#reader = 'REACH'\n",
    "for reading_file in reading_A_files:\n",
    "    output_file = f'output/{reader}' + '/' + reading_file.split('/')[-1].split('_reading_BioRECIPE')[0]\n",
    "    print(output_file)\n",
    "    time1 = time.time()\n",
    "    reading_df = preprocessing_reading(reading=reading_file, \n",
    "                                       evidence_score_cols=evidence_scoring_cols, \n",
    "                                       atts=attributes)\n",
    "    counter_A = {'corroboration': [], 'contradiction': []}\n",
    "    scored = score_reading(reading_df, \n",
    "                       model_A_df, \n",
    "                       graph_A, \n",
    "                       counter=counter_A,\n",
    "                       kind_values=kind_dict, \n",
    "                       match_values=match_dict, \n",
    "                       attributes=attributes, \n",
    "                       classify_scheme=approach,\n",
    "                       )\n",
    "    output(scored, output_file, kind_values=kind_dict)\n",
    "    print(time.time() - time1)\n",
    "    print('corroboration in model: {}'.format(len(set(counter_A['corroboration']))))\n",
    "    print('contradiction in model: {}'.format(len(set(counter_A['contradiction']))))\n",
    "\n",
    "for reading_file in reading_B_files:\n",
    "    output_file = f'output/{reader}' + '/' + reading_file.split('/')[-1].split('_reading_BioRECIPE')[0]\n",
    "    print(output_file)\n",
    "    time1 = time.time()\n",
    "    reading_df = preprocessing_reading(reading=reading_file, \n",
    "                                       evidence_score_cols=evidence_scoring_cols, \n",
    "                                       atts=attributes)\n",
    "    counter_B = {'corroboration': [], 'contradiction': []}\n",
    "    scored = score_reading(reading_df, \n",
    "                       model_B_df, \n",
    "                       graph_B, \n",
    "                       counter=counter_B,\n",
    "                       kind_values=kind_dict, \n",
    "                       match_values=match_dict, \n",
    "                       attributes=attributes, \n",
    "                       classify_scheme=approach)\n",
    "    output(scored, output_file, kind_values=kind_dict)\n",
    "    print(time.time() - time1)\n",
    "    print('corroboration in model: {}'.format(len(set(counter_B['corroboration']))))\n",
    "    print('contradiction in model: {}'.format(len(set(counter_B['contradiction']))))\n"
   ],
   "id": "a9a15d68aa6caf69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/LLAMA/RA4\n",
      "13\n",
      "0.27515578269958496\n",
      "corroboration in model: 0\n",
      "contradiction in model: 0\n",
      "output/LLAMA/RA3\n",
      "183\n",
      "1.5431809425354004\n",
      "corroboration in model: 2\n",
      "contradiction in model: 4\n",
      "output/LLAMA/RA2\n",
      "567\n",
      "3.1756250858306885\n",
      "corroboration in model: 3\n",
      "contradiction in model: 9\n",
      "output/LLAMA/RB_star_1\n",
      "163\n",
      "0.6803100109100342\n",
      "corroboration in model: 0\n",
      "contradiction in model: 0\n",
      "output/LLAMA/RB_star_2\n",
      "60\n",
      "0.37079811096191406\n",
      "corroboration in model: 0\n",
      "contradiction in model: 0\n",
      "output/LLAMA/RB1\n",
      "171\n",
      "0.7470047473907471\n",
      "corroboration in model: 0\n",
      "contradiction in model: 1\n",
      "output/LLAMA/RB2\n",
      "58\n",
      "0.3725299835205078\n",
      "corroboration in model: 0\n",
      "contradiction in model: 0\n",
      "output/LLAMA/RB3\n",
      "55\n",
      "0.34453916549682617\n",
      "corroboration in model: 0\n",
      "contradiction in model: 0\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TESTING task 1 & 2",
   "id": "a59405e7ba5be9c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Convert model format to interactions list to verify the corroborations",
   "id": "e30072099602b808"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T15:33:59.384600Z",
     "start_time": "2024-06-24T15:33:59.335487Z"
    }
   },
   "cell_type": "code",
   "source": "from translators.within_biorecipe.md_and_int import get_interactions_from_model",
   "id": "68feeb65dc742401",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T16:01:27.015520Z",
     "start_time": "2024-06-24T16:01:23.603913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attributes = ['Regulated Compartment ID', 'Regulator Compartment ID', 'Mechanism', 'Cell Line', 'Cell Type', 'Tissue Type', 'Organism']\n",
    "# Switch format\n",
    "interactions_A = os.getcwd() + '/input/interactions/translated_SkeMel133_biorecipe.xlsx'\n",
    "interactions_B = os.getcwd() + '/input/interactions/translated_ModelB_discrete_biorecipe.xlsx'\n",
    "\n",
    "get_interactions_from_model(os.getcwd() + '/' + model_files[0], interactions_A)\n",
    "get_interactions_from_model(os.getcwd() + '/' + model_files[1], interactions_B)\n",
    "\n",
    "interactions_A_df = pd.read_excel(interactions_A, index_col=None)\n",
    "interactions_B_df = pd.read_excel(interactions_B, index_col=None)"
   ],
   "id": "57353d146a9e7f08",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T16:01:29.346786Z",
     "start_time": "2024-06-24T16:01:27.612842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test in VIOLIN\n",
    "reading_A_df = preprocessing_reading(reading=interactions_A, \n",
    "                                     evidence_score_cols=evidence_scoring_cols, \n",
    "                                     atts=attributes)\n",
    "counter_A = {'corroboration': [], 'contradiction': []}\n",
    "scored = score_reading(reading_A_df, \n",
    "                       model_A_df, \n",
    "                       graph_A, \n",
    "                       counter=counter_A,\n",
    "                       kind_values=kind_dict, \n",
    "                       match_values=match_dict, \n",
    "                       attributes=attributes, \n",
    "                       classify_scheme=approach,\n",
    "                       )\n",
    "output_file = f'test/test_result' + '/' + interactions_A.split('/')[-1].split('_biorecipe')[0]\n",
    "output(scored, output_file, kind_values=kind_dict)\n",
    "print('corroboration in model: {}'.format(len(set(counter_A['corroboration']))))\n",
    "print('contradiction in model: {}'.format(len(set(counter_A['contradiction']))))\n",
    "\n",
    "reading_B_df = preprocessing_reading(reading=interactions_B,\n",
    "                                     evidence_score_cols=evidence_scoring_cols,\n",
    "                                     atts=attributes)\n",
    "counter_B = {'corroboration': [], 'contradiction': []}\n",
    "scored = score_reading(reading_B_df, \n",
    "                       model_B_df, \n",
    "                       graph_B, \n",
    "                       counter=counter_B,\n",
    "                       kind_values=kind_dict, \n",
    "                       match_values=match_dict, \n",
    "                       attributes=attributes, \n",
    "                       classify_scheme=approach)\n",
    "output_file = f'test/test_result' + '/' + interactions_B.split('/')[-1].split('_biorecipe')[0]\n",
    "output(scored, output_file, kind_values=kind_dict)\n",
    "print('corroboration in model: {}'.format(len(set(counter_B['corroboration']))))\n",
    "print('contradiction in model: {}'.format(len(set(counter_B['contradiction']))))\n"
   ],
   "id": "3a4b2ef88ede2c87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266\n",
      "corroboration in model: 264\n",
      "contradiction in model: 0\n",
      "72\n",
      "corroboration in model: 71\n",
      "contradiction in model: 0\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TESTING Task 3 & 4",
   "id": "802a81a2305cd9d0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Randomly sampled several interactions to test if VIOLIN can get corroborations",
   "id": "1754c952797a7251"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T14:14:07.637731Z",
     "start_time": "2024-06-24T14:14:07.394916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Randomly choose some interactions from modelA\n",
    "import random \n",
    "random.seed(10)\n",
    "\n",
    "random_A_df = reading_A_df.sample(n=50).reset_index()\n",
    "random_B_df = reading_B_df.sample(n=25).reset_index()\n",
    "\n",
    "counter_A = {'corroboration': [], 'contradiction': []}\n",
    "scored = score_reading(random_A_df, \n",
    "                       model_A_df, \n",
    "                       graph_A, \n",
    "                       counter=counter_A,\n",
    "                       kind_values=kind_dict, \n",
    "                       match_values=match_dict, \n",
    "                       attributes=attributes, \n",
    "                       classify_scheme=approach,\n",
    "                       )\n",
    "output_file = f'test/test_result' + '/' + interactions_A.split('/')[-1].split('_biorecipe')[0]\n",
    "output(scored, output_file, kind_values=kind_dict)\n",
    "print('corroboration in model: {}'.format(len(set(counter_A['corroboration']))))\n",
    "print('contradiction in model: {}'.format(len(set(counter_A['contradiction']))))\n",
    "\n",
    "counter_B = {'corroboration': [], 'contradiction': []}\n",
    "scored = score_reading(random_B_df, \n",
    "                       model_B_df, \n",
    "                       graph_B, \n",
    "                       counter=counter_B,\n",
    "                       kind_values=kind_dict, \n",
    "                       match_values=match_dict, \n",
    "                       attributes=attributes, \n",
    "                       classify_scheme=approach)\n",
    "output_file = f'test/test_result' + '/' + interactions_B.split('/')[-1].split('_biorecipe')[0]\n",
    "output(scored, output_file, kind_values=kind_dict)\n",
    "print('corroboration in model: {}'.format(len(set(counter_B['corroboration']))))\n",
    "print('contradiction in model: {}'.format(len(set(counter_B['contradiction']))))\n"
   ],
   "id": "42e1e7efdd4cbf19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "corroboration in model: 50\n",
      "contradiction in model: 0\n",
      "25\n",
      "corroboration in model: 25\n",
      "contradiction in model: 0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### TESTING Task 5 & 6 ",
   "id": "36d7d71e192d7127"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Use RA2.0.1.1 to verify if VIOLIN can get extensions correctly",
   "id": "c724cf2e6585eccf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T14:14:10.453357Z",
     "start_time": "2024-06-24T14:14:07.639832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import RA2.0.1.1 to verify the extension\n",
    "extension_reading = os.getcwd() + '/'+ 'input/interactions/example/RA2_0_1_1_reading_BioRECIPE.xlsx'\n",
    "extension_A_df = preprocessing_reading(reading=extension_reading, \n",
    "                                     evidence_score_cols=evidence_scoring_cols, \n",
    "                                     atts=attributes)\n",
    "counter_A = {'corroboration': [], 'contradiction': []}\n",
    "scored = score_reading(extension_A_df, \n",
    "                       model_A_df, \n",
    "                       graph_A, \n",
    "                       counter=counter_A, \n",
    "                       kind_values=kind_dict, \n",
    "                       match_values=match_dict, \n",
    "                       attributes=attributes, \n",
    "                       classify_scheme=approach, \n",
    "                       )\n",
    "output_file = f'test/test_result' + '/' + extension_reading.split('/')[-1].split('_reading_BioRECIPE')[0]\n",
    "output(scored, output_file, kind_values=kind_dict)\n",
    "print('corroboration in model: {}'.format(len(set(counter_A['corroboration']))))\n",
    "print('contradiction in model: {}'.format(len(set(counter_A['contradiction']))))"
   ],
   "id": "597203d3387b1fd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006\n",
      "corroboration in model: 23\n",
      "contradiction in model: 13\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TESTING Task 7&8",
   "id": "4ad6047f220d82b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### FLUTE reading files",
   "id": "b0fda8a15fed78dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T18:18:41.472018Z",
     "start_time": "2024-06-25T18:18:41.422996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import httplib2 as http\n",
    "import json\n",
    "import time\n",
    "\n",
    "try:\n",
    "    from urlparse import urlparse\n",
    "except ImportError:\n",
    "    from urllib.parse import urlparse \n",
    "    \n",
    "headers = {\n",
    "    \"Accept\": 'application/json'\n",
    "}\n",
    "\n",
    "h = http.Http()\n",
    "def get_hgnc_symbol(hgnc_id, url='https://rest.genenames.org/fetch/hgnc_id'):\n",
    "    response, content = h.request(\n",
    "    url+f'/{hgnc_id}',\n",
    "    'GET',\n",
    "    '',\n",
    "    headers\n",
    "    )\n",
    "    print(hgnc_id)\n",
    "    data = json.loads(content)\n",
    "    status_code = False; i = 0; symbol = ''\n",
    "    while status_code != True and i < 10:\n",
    "        try:\n",
    "            i += 1\n",
    "            response, content = h.request(\n",
    "                url+f'/{hgnc_id}',\n",
    "                'GET',\n",
    "                '',\n",
    "                headers)\n",
    "            \n",
    "            if response['status'] == '200':\n",
    "                symbol = data['response']['docs'][0]['symbol']\n",
    "                status_code = True\n",
    "            else:\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(1)\n",
    "            \n",
    "    return symbol"
   ],
   "id": "ab2dfd80aa19095",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T18:18:59.048283Z",
     "start_time": "2024-06-25T18:18:46.940344Z"
    }
   },
   "cell_type": "code",
   "source": "j = get_hgnc_symbol(11803)",
   "id": "b1cc2583b449635f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11803\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T16:41:21.156170Z",
     "start_time": "2024-06-25T16:41:21.104955Z"
    }
   },
   "cell_type": "code",
   "source": "re.findall(r'[0-9]+', 'HGNC: 5464')[0]",
   "id": "a03d0695c613cdbd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5464'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dict_ = {}",
   "id": "65f64473bea3dd39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T02:01:07.109647Z",
     "start_time": "2024-06-26T02:00:56.577875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Switch HGNC ID to HGNC symbol\n",
    "for machine in ['INDRA']:\n",
    "    for file in glob.glob(f'input/interactions/FLUTE/{machine}/*.xlsx'):\n",
    "        if 'grd_ints_scores' in file:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            df = pd.read_excel(file)\n",
    "            basename = file.split('/')[-1]\n",
    "            print(basename)\n",
    "            if 'Regulated HGNC ID' in df.columns:\n",
    "                list_ = []\n",
    "                for x in df['Regulated HGNC ID'].to_list():\n",
    "                    if len(re.findall(r'[0-9]+', str(x))) != 0:\n",
    "                        x_id = re.findall(r'[0-9]+', str(x))[0]\n",
    "                        if x_id in list(dict_.keys()):\n",
    "                            list_.append(dict_[x_id])\n",
    "                        else:\n",
    "                            if x_id != '':\n",
    "                                dict_[x_id] = get_hgnc_symbol(x_id)\n",
    "                                list_.append(dict_[x_id])\n",
    "                            else: pass\n",
    "\n",
    "                    else:\n",
    "                        list_.append('')\n",
    "                df['Regulated HGNC Symbol'] = list_\n",
    "                df.drop('Regulated HGNC ID', inplace=True, axis=1)\n",
    "            else:\n",
    "                pass \n",
    "            \n",
    "            if 'Regulator HGNC ID' in df.columns:\n",
    "                list_ = []\n",
    "                for x in df['Regulator HGNC ID'].to_list():\n",
    "                    if len(re.findall(r'[0-9]+', str(x))) != 0:\n",
    "                        x_id = re.findall(r'[0-9]+', str(x))[0]\n",
    "                        if x_id in list(dict_.keys()):\n",
    "                            list_.append(dict_[x_id])\n",
    "                        else:\n",
    "                            if x_id != '':\n",
    "                                dict_[x_id] = get_hgnc_symbol(x_id)\n",
    "                                list_.append(dict_[x_id])\n",
    "                            else: pass\n",
    "\n",
    "                    else:\n",
    "                        list_.append('')\n",
    "                df['Regulator HGNC Symbol'] = list_\n",
    "                df.drop('Regulator HGNC ID', inplace=True, axis=1)\n",
    "            \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            df.to_excel(file, index=False)"
   ],
   "id": "21ed66276e6a0614",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB2_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "RA4_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "RB3_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "RB1_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "RA1_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "RA2_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "RA3_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "RB_star_2_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "RB_star_1_reading_BioRECIPE_FLUTE_filtered.xlsx\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dict_",
   "id": "c36f4c732b48e321",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### test tab data ",
   "id": "6c2fcd5583a06f79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T22:49:43.523077Z",
     "start_time": "2024-06-25T22:49:08.825901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testing_A_readings = [\"RA2\",\n",
    "                    \"RA21\",\n",
    "                    \"RA2_0_1\",\n",
    "                    \"RA2_0_1_1\"]\n",
    "testing_A_readings = [f'input/interactions/example/{x}_reading_BioRECIPE.xlsx' for x in testing_A_readings]\n",
    "\n",
    "testing_B_readings = [\"RB2\",\n",
    "                      \"RB21\",\n",
    "                      \"RB2_0_1\"]\n",
    "testing_B_readings = [f'input/interactions/example/{x}_reading_BioRECIPE.xlsx' for x in testing_B_readings]\n",
    "\n",
    "for reading_file in testing_A_readings:\n",
    "    output_file = f'test/test_result' + '/' + reading_file.split('/')[-1].split('_reading_BioRECIPE')[0]\n",
    "    print(output_file)\n",
    "    time1 = time.time()\n",
    "    reading_df = preprocessing_reading(reading=reading_file,\n",
    "                                       evidence_score_cols=evidence_scoring_cols,\n",
    "                                       atts=attributes)\n",
    "    counter_A = {'corroboration': [], 'contradiction': []}\n",
    "    scored = score_reading(reading_df,\n",
    "                           model_A_df,\n",
    "                           graph_A,\n",
    "                           counter=counter_A,\n",
    "                           kind_values=kind_dict,\n",
    "                           match_values=match_dict,\n",
    "                           attributes=attributes,\n",
    "                           classify_scheme=approach,\n",
    "                           )\n",
    "    output(scored, output_file, kind_values=kind_dict)\n",
    "    print(time.time() - time1)\n",
    "    print('corroboration in model: {}'.format(len(set(counter_A['corroboration']))))\n",
    "    print('contradiction in model: {}'.format(len(set(counter_A['contradiction']))))\n",
    "\n",
    "for reading_file in testing_B_readings:\n",
    "    output_file = f'test/test_result' + '/' + reading_file.split('/')[-1].split('_reading_BioRECIPE')[0]\n",
    "    print(output_file)\n",
    "    time1 = time.time()\n",
    "    reading_df = preprocessing_reading(reading=reading_file,\n",
    "                                       evidence_score_cols=evidence_scoring_cols,\n",
    "                                       atts=attributes)\n",
    "    counter_B = {'corroboration': [], 'contradiction': []}\n",
    "    scored = score_reading(reading_df,\n",
    "                           model_B_df,\n",
    "                           graph_B,\n",
    "                           counter=counter_B,\n",
    "                           kind_values=kind_dict,\n",
    "                           match_values=match_dict,\n",
    "                           attributes=attributes,\n",
    "                           classify_scheme=approach)\n",
    "    output(scored, output_file, kind_values=kind_dict)\n",
    "    print(time.time() - time1)\n",
    "    print('corroboration in model: {}'.format(len(set(counter_B['corroboration']))))\n",
    "    print('contradiction in model: {}'.format(len(set(counter_B['contradiction']))))\n"
   ],
   "id": "fae6be6147162b58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/test_result/RA2\n",
      "5725\n",
      "18.219555139541626\n",
      "corroboration in model: 34\n",
      "contradiction in model: 32\n",
      "test/test_result/RA21\n",
      "918\n",
      "3.2124831676483154\n",
      "corroboration in model: 9\n",
      "contradiction in model: 19\n",
      "test/test_result/RA2_0_1\n",
      "2584\n",
      "8.524222373962402\n",
      "corroboration in model: 31\n",
      "contradiction in model: 26\n",
      "test/test_result/RA2_0_1_1\n",
      "1006\n",
      "3.481868028640747\n",
      "corroboration in model: 23\n",
      "contradiction in model: 13\n",
      "test/test_result/RB2\n",
      "163\n",
      "0.524526834487915\n",
      "corroboration in model: 9\n",
      "contradiction in model: 1\n",
      "test/test_result/RB21\n",
      "37\n",
      "0.2357780933380127\n",
      "corroboration in model: 0\n",
      "contradiction in model: 0\n",
      "test/test_result/RB2_0_1\n",
      "102\n",
      "0.4438438415527344\n",
      "corroboration in model: 5\n",
      "contradiction in model: 0\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### FLUTE tab data",
   "id": "b67cc572bcd580de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T21:39:31.193567Z",
     "start_time": "2024-07-14T21:39:16.683213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attributes = [\"Regulated Compartment\", \"Regulator Compartment\"]\n",
    "\n",
    "#for machine in ['gpt', 'INDRA', 'LLAMA', 'REACH']:\n",
    "for machine in ['gpt']:\n",
    "    print(f'=================={machine}=================')\n",
    "    for file in glob.glob(f'input/interactions/FLUTE/{machine}/*.xlsx'):\n",
    "        if 'grd_ints_scores' in file:\n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            output_file = f'output/FLUTE' + f'/{machine}/' + file.split('/')[-1].split('_reading_BioRECIPE')[0]\n",
    "            df = pd.read_excel(file)\n",
    "            basename = file.split('/')[-1]\n",
    "            print(basename)\n",
    "            # Choose model dataframe\n",
    "            if re.findall(r'^RA', basename):\n",
    "                model_df = model_A_df\n",
    "                graph = graph_A\n",
    "            else:\n",
    "                model_df = model_B_df\n",
    "                graph = graph_B\n",
    "            print(f'model length: {len(model_df)}')\n",
    "            # process through VIOLIN \n",
    "            time1 = time.time()\n",
    "            reading_df = preprocessing_reading(reading=file,\n",
    "                                               evidence_score_cols=evidence_scoring_cols,\n",
    "                                               atts=attributes)\n",
    "            counter_ = {'corroboration': [], 'contradiction': []}\n",
    "            scored = score_reading(reading_df,\n",
    "                                   model_df,\n",
    "                                   graph,\n",
    "                                   counter=counter_,\n",
    "                                   kind_values=kind_dict,\n",
    "                                   match_values=match_dict,\n",
    "                                   attributes=attributes,\n",
    "                                   classify_scheme=approach)\n",
    "            output(scored, output_file, kind_values=kind_dict)\n",
    "            print(time.time() - time1)\n",
    "            print('corroboration in model: {}'.format(len(set(counter_['corroboration']))))\n",
    "            print('contradiction in model: {}'.format(len(set(counter_['contradiction']))))1"
   ],
   "id": "b78eacb460339779",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================gpt=================\n",
      "RB2_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "model length: 39\n",
      "104\n",
      "0.4778470993041992\n",
      "corroboration in model: 1\n",
      "contradiction in model: 1\n",
      "RA4_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "model length: 179\n",
      "8\n",
      "0.15981507301330566\n",
      "corroboration in model: 1\n",
      "contradiction in model: 0\n",
      "RB3_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "model length: 39\n",
      "66\n",
      "0.41270875930786133\n",
      "corroboration in model: 0\n",
      "contradiction in model: 2\n",
      "RB1_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "model length: 39\n",
      "259\n",
      "0.964310884475708\n",
      "corroboration in model: 0\n",
      "contradiction in model: 1\n",
      "RA2_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "model length: 179\n",
      "1158\n",
      "7.202918767929077\n",
      "corroboration in model: 18\n",
      "contradiction in model: 37\n",
      "RA3_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "model length: 179\n",
      "254\n",
      "1.7872989177703857\n",
      "corroboration in model: 4\n",
      "contradiction in model: 10\n",
      "RB_star_2_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "model length: 39\n",
      "58\n",
      "0.3278920650482178\n",
      "corroboration in model: 0\n",
      "contradiction in model: 0\n",
      "RB_star_1_reading_BioRECIPE_FLUTE_filtered.xlsx\n",
      "model length: 39\n",
      "191\n",
      "1.0339760780334473\n",
      "corroboration in model: 0\n",
      "contradiction in model: 0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TESTING TASK 9 & 10",
   "id": "fe161167e7cfc331"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Randomly added contradiction interactions to see if there is any influence on mixing",
   "id": "99af4fdfb3bc0aa2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T21:38:46.555464Z",
     "start_time": "2024-06-24T21:38:41.542190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testing_A_readings = [\"translated_SkeMel133_biorecipe.xlsx\",\n",
    "                    \"translated_SkeMel133_biorecipe_combined_10contradictions.xlsx\",\n",
    "                    \"translated_SkeMel133_biorecipe_combined_10randoms.xlsx\"]\n",
    "testing_A_readings = [f'input/interactions/{x}' for x in testing_A_readings]\n",
    "\n",
    "testing_B_readings = [\"translated_ModelB_discrete_biorecipe.xlsx\",\n",
    "                      \"translated_ModelB_discrete_biorecipe_combined_10contradictions.xlsx\",\n",
    "                      \"translated_ModelB_discrete_biorecipe_combined_10randoms.xlsx\"]\n",
    "testing_B_readings = [f'input/interactions/{x}' for x in testing_B_readings]\n",
    "\n",
    "for reading_file in testing_A_readings:\n",
    "    output_file = f'test/test_result' + '/' + reading_file.split('/')[-1].split('.')[0]\n",
    "    print(output_file)\n",
    "    time1 = time.time()\n",
    "    reading_df = preprocessing_reading(reading=reading_file,\n",
    "                                       evidence_score_cols=evidence_scoring_cols,\n",
    "                                       atts=attributes)\n",
    "    counter_A = {'corroboration': [], 'contradiction': []}\n",
    "    scored = score_reading(reading_df,\n",
    "                           model_A_df,\n",
    "                           graph_A,\n",
    "                           counter=counter_A,\n",
    "                           kind_values=kind_dict,\n",
    "                           match_values=match_dict,\n",
    "                           attributes=attributes,\n",
    "                           classify_scheme=approach,\n",
    "                           )\n",
    "    output(scored, output_file, kind_values=kind_dict)\n",
    "    print(time.time() - time1)\n",
    "    print('corroboration in model: {}'.format(len(set(counter_A['corroboration']))))\n",
    "    print('contradiction in model: {}'.format(len(set(counter_A['contradiction']))))\n",
    "\n",
    "for reading_file in testing_B_readings:\n",
    "    output_file = f'test/test_result' + '/' + reading_file.split('/')[-1].split('.')[0]\n",
    "    print(output_file)\n",
    "    time1 = time.time()\n",
    "    reading_df = preprocessing_reading(reading=reading_file,\n",
    "                                       evidence_score_cols=evidence_scoring_cols,\n",
    "                                       atts=attributes)\n",
    "    counter_B = {'corroboration': [], 'contradiction': []}\n",
    "    scored = score_reading(reading_df,\n",
    "                           model_B_df,\n",
    "                           graph_B,\n",
    "                           counter=counter_B,\n",
    "                           kind_values=kind_dict,\n",
    "                           match_values=match_dict,\n",
    "                           attributes=attributes,\n",
    "                           classify_scheme=approach)\n",
    "    output(scored, output_file, kind_values=kind_dict)\n",
    "    print(time.time() - time1)\n",
    "    print('corroboration in model: {}'.format(len(set(counter_B['corroboration']))))\n",
    "    print('contradiction in model: {}'.format(len(set(counter_B['contradiction']))))"
   ],
   "id": "57c96fa318748bfe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/test_result/translated_SkeMel133_biorecipe\n",
      "266\n",
      "1.4218220710754395\n",
      "corroboration in model: 264\n",
      "contradiction in model: 0\n",
      "test/test_result/translated_SkeMel133_biorecipe_combined_10contradictions\n",
      "276\n",
      "1.0342469215393066\n",
      "corroboration in model: 264\n",
      "contradiction in model: 5\n",
      "test/test_result/translated_SkeMel133_biorecipe_combined_10randoms\n",
      "275\n",
      "1.3475852012634277\n",
      "corroboration in model: 264\n",
      "contradiction in model: 1\n",
      "test/test_result/translated_ModelB_discrete_biorecipe\n",
      "72\n",
      "0.28899717330932617\n",
      "corroboration in model: 71\n",
      "contradiction in model: 0\n",
      "test/test_result/translated_ModelB_discrete_biorecipe_combined_10contradictions\n",
      "83\n",
      "0.28201889991760254\n",
      "corroboration in model: 71\n",
      "contradiction in model: 4\n",
      "test/test_result/translated_ModelB_discrete_biorecipe_combined_10randoms\n",
      "83\n",
      "0.5087399482727051\n",
      "corroboration in model: 71\n",
      "contradiction in model: 0\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f3d1612e3f6b8140"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
